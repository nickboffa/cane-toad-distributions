---
title: "Data Cleaning"
author: "Nicholas Boffa u7686660"
date: "2024-04-28"
output: html_document
---

# Load Libraries

```{r load-libraries}
library(tidyverse)
library(raster)
library(knitr)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Create Raster Brick
## Download .txt files

To obtain original .txt data, from the web:

1. Click the link for each file type, specified in the *table* below
2. Find the text saying "Download: Grid"
3. Click on the hyperlinked "Grid" to download


```{r}
table <- data.frame(
  Measurement = c("Mean Winter Temperature", "Mean Summer Rainfall", "Mean Winter Rainfall", "Mean Annual Relative Humidity at 9am"),
  Period = c("June to August 1991 to 2020", "December to February 1991 to 2020", "June to August 1991 to 2020", "1976 to 2005"),
  Link = c("[Mean Winter Temperature Data](http://www.bom.gov.au/climate/maps/averages/temperature/?maptype=mean&period=win&region=aus)",
           "[Mean Summer Rainfall Data](http://www.bom.gov.au/climate/maps/averages/rainfall/?period=sum&region=aus)",
           "[Mean Winter Rainfall Data](http://www.bom.gov.au/climate/maps/averages/rainfall/?period=win&region=aus)",
           "[Mean Annual Relative Humidity at 9am Data](http://www.bom.gov.au/climate/maps/averages/relative-humidity/)")
)

# Display table using kable
kable(table, format = "html", escape = FALSE)
```


## Load raster layers and make stack
```{r create-raster-brick}
mean_win_temp <- raster("raw_data/climate/mean_winter_temp.txt")
rel_humidity <- raster("raw_data/climate/rel_humidity_9am.txt")
mean_win_rain <- raster("raw_data/climate/mean_winter_rainfall.txt")
mean_sum_rain <- raster("raw_data/climate/mean_summer_rainfall.txt")

rasters <- list(mean_win_temp, rel_humidity, mean_win_rain, mean_sum_rain)

# Find max resolution raster
max_res <- max(res(mean_win_temp), res(rel_humidity), 
                  res(mean_win_rain), res(mean_sum_rain))

max_res_index <- which.max(c(res(mean_win_temp), res(rel_humidity), res(mean_win_rain), res(mean_sum_rain)))

max_res_raster <- rasters[[max_res_index]]

# Resample rasters to the extent and resolution of raster with max res
mean_win_temp <- resample(mean_win_temp, max_res_raster, method = "bilinear")
rel_humidity <- resample(rel_humidity, max_res_raster, method = "bilinear")
mean_win_rain <- resample(mean_win_rain, max_res_raster, method = "bilinear")
mean_sum_rain <- resample(mean_sum_rain, max_res_raster, method = "bilinear")

# Give themm all australia shape, using the fact that mean_win_temp is shaped like Australia

rel_humidity[is.na(mean_win_temp)] <- NA
mean_win_rain[is.na(mean_win_temp)] <- NA
mean_sum_rain[is.na(mean_win_temp)] <- NA

# Create a raster brick
climate_stack <- stack(mean_win_temp, rel_humidity, mean_win_rain, mean_sum_rain)
names(climate_stack) <- c("mean_win_temp", "rel_humidity", "mean_win_rain", "mean_sum_rain")

# set resolution
desired_res <- 0.4
fact <- desired_res/res(climate_stack)
climate_stack <- aggregate(climate_stack, fact=fact)

plot(climate_stack)


writeRaster(climate_stack, filename="processed_data/climate_stack.grd", overwrite=TRUE)
rm(list = c("mean_sum_rain", "mean_win_rain", "rel_humidity", "max_res_raster", "rasters")) # need mean_win_
```

Might be able to use model in:
raster::predict(climate_stack, model, type='response')

And now we can save it processed_data for easy creation later on.
## Create australia raster for cleaning
```{r}
australia_raster <- raster(extent(mean_win_temp), res = res(mean_win_temp))

# Set values to 1 where "mean_win_temp" is not NA, and 0 otherwise
australia_raster[] <- NA

# Set values to 1 where "mean_win_temp" is not NA, and 0 otherwise
australia_raster[!is.na(mean_win_temp)] <- 1
australia_raster[is.na(mean_win_temp)] <- 0
```

# Prepare Data

## Load raw data

Downloaded by ALA, with default settings on (e.g. spatially suspect records were excluded)
```{r}
toads <- read_csv("raw_data/occurrence/rhinella-marina-occurence.csv")
```
Could geo-reference the missing coordinate observations using the 'locality' column

```{r}
length(toads[!(!is.na(toads$decimalLatitude) & !is.na(toads$decimalLongitude)),])
```




## Clean Data

```{r}
clean <- toads |> 
  filter(country == "Australia" & !is.na(decimalLatitude) & !is.na(decimalLongitude))
clean
```

```{r}
georef <- subset(clean, (is.na(decimalLongitude) | is.na(decimalLatitude)) & ! is.na(locality) ) |> 
  dplyr::select(rightsHolder, stateProvince, locality, eventDate)
georef
```
So there are only 73 rows that could be georeferenced. According to https://docs.gbif.org/georeferencing-best-practices/1.0/en/ however, it is better to not georeference at all than georeference poorly. Given this data is so old

```{r}
cutoff <- function(x) {-0.5*x + 40}
ggplot(toads, aes(x=decimalLongitude, y=decimalLatitude, color=country)) +
  geom_point() +
  stat_function(fun=cutoff, colour='red')
```

```{r}
sp_clean <- clean
coordinates(sp_clean) <- c("decimalLongitude", "decimalLatitude")
```

Only take values on land

```{r}
is_land <- extract(australia_raster, sp_clean)

# Filter rows in the spatial data frame based on the raster values
clean <- clean[which(is_land == 1),]
```

REMOVED clean[which(is_land != 1),] ROWS

```{r}
cutoff <- function(x) {-0.5*x + 40}
ggplot(clean, aes(x=decimalLongitude, y=decimalLatitude)) +
  geom_point() +
  stat_function(fun=cutoff, colour='red')
```

Going to remove observations below the red line:

```{r}
clean <- clean |> 
  filter(decimalLatitude - cutoff(decimalLongitude) >= 0) # above red line above
```

```{r}
ggplot(clean, aes(x=decimalLongitude, y=decimalLatitude)) +
  geom_point()
```

Finally, there are no cane toads in Central Australia

```{r}
clean <- clean |> 
  filter(!(decimalLongitude < 135 & decimalLatitude < -22))
```

```{r}
ggplot(clean, aes(x=decimalLongitude, y=decimalLatitude)) +
  geom_point()
```

I'm happy with this! Would like to automate cleaning a bit further, by determining clusters? I'm sure there's a function online to do it easily.

## Create main df

Now create main dataframe
```{r}
df <- clean |> 
  dplyr::select(eventDate, year, stateProvince, locality, decimalLongitude, decimalLatitude,) |> 
  arrange(eventDate)
df <- df |> 
  rename(longitude = decimalLongitude,
         latitude = decimalLatitude)

df <- df[(!is.na(df$latitude) & !is.na(df$longitude)),]
sp_df <- df
coordinates(sp_df) <- c("longitude", "latitude")

head(sp_df)
```


```{r}
counts <- rasterize(sp_df, climate_stack, fun = "count", background=0) # cells without observation get a 0
toad_counts <- counts[["ID"]] # 1 per individual row
toad_count_df <- as.data.frame(toad_counts, xy = TRUE)
plot(toad_counts)
```


## EDA of df


There is no absence data:
```{r}
unique(toads$occurrenceStatus)
```

1900 records are likely wrong (1900-01-01?), In fact, an odd number of records occur on the first day of the month.

```{r}
head(df)
```

```{r}
ggplot(df, aes(x=yday(eventDate))) +
  geom_histogram()
```

```{r}
library(skimr)
library(GGally)
```
```{r}
skim(df)
```
```{r, warning=F, message=F}
df |> 
  dplyr::select(-locality) |> 
  ggpairs()
```
```{r}
ggplot(df, aes(x=longitude, y=latitude)) +
  geom_point()
```



```{r}
toads |> 
  arrange(eventDate) |> 
  head()
```

df <- df[(!is.na(df$decimalLatitude) & !is.na(df$decimalLongitude)),]
```

```{r create-cells}
create_cell_df <- function(data, years_to=2024, res=0.5) {
  empty_raster <- raster(extent(mean_win_temp), res = res)
  values(empty_raster) <- 0
  
  cell_df <- as.data.frame(xyFromCell(empty_raster, 1:ncell(empty_raster)))
  colnames(cell_df) <- c("decimalLongitude", "decimalLatitude")
  
  cell_df$mean_win_temp <- extract(mean_win_temp, cell_df[, c("decimalLongitude", "decimalLatitude")])
  cell_df$rel_humidity <- extract(rel_humidity, cell_df[, c("decimalLongitude", "decimalLatitude")])
  cell_df$mean_win_rain <- extract(mean_win_rain, cell_df[, c("decimalLongitude", "decimalLatitude")])
  cell_df$mean_sum_rain <- extract(mean_sum_rain, cell_df[, c("decimalLongitude", "decimalLatitude")])

  cell_df <- na.omit(cell_df)
  rownames(cell_df) <- NULL
  cell_df$toads <- rep(0, nrow(cell_df))
  
  data_upto_date <- subset(df, year <= years_to) # filter won't work if it's a spatial points df
  
  for (i in seq_len(nrow(data_upto_date))) {
    given_lat <- data_upto_date$decimalLatitude[i]
    given_lon <- data_upto_date$decimalLongitude[i]
    
    # Get the cell index of the nearest cell
    cell_index <- cellFromXY(empty_raster, c(given_lon, given_lat))
  
    # Get the latitude and longitude of the nearest cell
    nearest_lat_lon <- xyFromCell(empty_raster, cell_index)
    
    row_index <- which(cell_df$decimalLatitude == nearest_lat_lon[2] & cell_df$decimalLongitude == nearest_lat_lon[1])
    
    # Increment the toads count in the corresponding row
    cell_df[row_index, "toads"] <- cell_df[row_index, "toads"] + 1
  }
  
  cell_df$ribbit <- cell_df$toads > 0
  
  return(cell_df)
}
```

```{r}
unique(subset(df, year <= 2000)$year)
```

```{r}
cell_df <- create_cell_df(df, years_to=2024, res=0.5)
head(cell_df)
```



```{r}
ggplot(cell_df, aes(x=decimalLongitude, y=decimalLatitude, color=log10(toads))) +
  geom_point(size=1.8) +
  viridis::scale_color_viridis()
```
Could remove data from clear outlier observations?

What about data before 2010?




# Machine Learning

```{r}
library(randomForest)
library(caTools)
```


```{r}
run_model <- function(data) {
  set.seed(12345)

  split <- sample.split(data, SplitRatio = 0.7) 
    
  train <- subset(data, split == "TRUE") 
  test <- subset(data, split == "FALSE") 
  
  model <- randomForest(toads ~ mean_win_rain + mean_win_temp + mean_sum_rain + rel_humidity, data = train)
  
  return(model)
}
```


```{r}
set.seed(12345)

split <- sample.split(cell_df, SplitRatio = 0.7) 
  
train <- subset(cell_df, split == "TRUE") 
test <- subset(cell_df, split == "FALSE") 
```

```{r}
# Define the models
model <- randomForest(toads ~ mean_win_rain + mean_win_temp + mean_sum_rain + rel_humidity, data = train)
model2 <- randomForest(ribbit ~ mean_win_rain + mean_win_temp + mean_sum_rain + rel_humidity, data = train)
```

```{r}
test$model_toads <- predict(model, test)
test$model2_toads <- predict(model2, test)
```

```{r}
cell_df$predicted <- predict(model, cell_df)
cell_df$predicted2 <- predict(model2, cell_df)
```



```{r}
confusion_mtx = table(test$toads,test$model_toads) 
```

```{r}
# Plotting model 
plot(model2) 
  
# Importance plot 
importance(model2) 
  
# Variable importance plot 
varImpPlot(model2) 
```

Model 2 is way better?

```{r}
hist(log10(cell_df$predicted))
```


```{r}
ggplot(train, aes(x=decimalLongitude, y=decimalLatitude, color=toads)) +
  geom_point()
```

```{r}
cell_df |> 
  ggplot(aes(x=decimalLongitude, y=decimalLatitude, colour=log10(predicted))) +
    geom_point() +
    geom_point(data=cell_df |> filter(predicted < 0.5), colour='grey') +
    viridis::scale_color_viridis()
```

```{r}
millenium |> 
  ggplot(aes(x=decimalLongitude, y=decimalLatitude, colour=log10(predicted))) +
    geom_point() +
    geom_point(data=millenium |> filter(predicted < 0.2), colour='grey') +
    viridis::scale_color_viridis()
```


```{r}
test |> 
  ggplot(aes(x=decimalLongitude, y=decimalLatitude, colour=model2_toads)) +
    geom_point() +
    #geom_point(data=cell_df |> filter(predicted2 < 0.5), colour='grey') +
    viridis::scale_color_viridis()
```




# Future Predicting 

```{r}
millenium <- create_cell_df(df, years_to=2000, res=0.5)
head(millenium)



mill_model <- run_model(millenium)

millenium$predicted <- predict(mill_model, millenium)

ggplot(millenium, aes(x=decimalLongitude, y=decimalLatitude, color=log10(predicted))) +
  geom_point(size=1.8) +
  viridis::scale_color_viridis()
```



Varroa mites
Fire ants
Proximate Bayesian Modelling
Use already-made shapefiles of cane toad distributions

Amniote life history database


http://www.bom.gov.au/climate/maps/averages/rainfall/
