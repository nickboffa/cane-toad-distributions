---
title: "Data Cleaning"
author: "Nicholas Boffa u7686660"
date: "2024-04-28"
output: html_document
---

# Load Libraries

```{r load-libraries}
library(tidyverse)
library(raster)
library(knitr)
library(randomForest)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Create Raster Brick
## Download .txt files

To obtain original .txt data, from the web:

1. Click the link for each file type, specified in the *table* below
2. Find the text saying "Download: Grid"
3. Click on the hyperlinked "Grid" to download


```{r}
table <- data.frame(
  Measurement = c("Mean Winter Temperature", "Mean Summer Rainfall", "Mean Winter Rainfall", "Mean Annual Relative Humidity at 9am"),
  Period = c("June to August 1991 to 2020", "December to February 1991 to 2020", "June to August 1991 to 2020", "1976 to 2005"),
  Link = c("[Mean Winter Temperature Data](http://www.bom.gov.au/climate/maps/averages/temperature/?maptype=mean&period=win&region=aus)",
           "[Mean Summer Rainfall Data](http://www.bom.gov.au/climate/maps/averages/rainfall/?period=sum&region=aus)",
           "[Mean Winter Rainfall Data](http://www.bom.gov.au/climate/maps/averages/rainfall/?period=win&region=aus)",
           "[Mean Annual Relative Humidity at 9am Data](http://www.bom.gov.au/climate/maps/averages/relative-humidity/)")
)

# Display table using kable
kable(table, format = "html", escape = FALSE)
```


## Load raster layers and make stack
```{r create-raster-brick}
mean_win_temp <- raster("raw_data/climate/mean_winter_temp.txt")
rel_humidity <- raster("raw_data/climate/rel_humidity_9am.txt")
mean_win_rain <- raster("raw_data/climate/mean_winter_rainfall.txt")
mean_sum_rain <- raster("raw_data/climate/mean_summer_rainfall.txt")

rasters <- list(mean_win_temp, rel_humidity, mean_win_rain, mean_sum_rain)

# Find max resolution raster
max_res <- max(res(mean_win_temp), res(rel_humidity), 
                  res(mean_win_rain), res(mean_sum_rain))

max_res_index <- which.max(c(res(mean_win_temp), res(rel_humidity), res(mean_win_rain), res(mean_sum_rain)))

max_res_raster <- rasters[[max_res_index]]

# Resample rasters to the extent and resolution of raster with max res
mean_win_temp <- resample(mean_win_temp, max_res_raster, method = "bilinear")
rel_humidity <- resample(rel_humidity, max_res_raster, method = "bilinear")
mean_win_rain <- resample(mean_win_rain, max_res_raster, method = "bilinear")
mean_sum_rain <- resample(mean_sum_rain, max_res_raster, method = "bilinear")

# Give themm all australia shape, using the fact that mean_win_temp is shaped like Australia

rel_humidity[is.na(mean_win_temp)] <- NA
mean_win_rain[is.na(mean_win_temp)] <- NA
mean_sum_rain[is.na(mean_win_temp)] <- NA

# Create a raster brick
climate_stack <- stack(mean_win_temp, rel_humidity, mean_win_rain, mean_sum_rain)
names(climate_stack) <- c("mean_win_temp", "rel_humidity", "mean_win_rain", "mean_sum_rain")

# set resolution
desired_res <- 0.4
fact <- desired_res/res(climate_stack)
climate_stack <- aggregate(climate_stack, fact=fact)

plot(climate_stack)


writeRaster(climate_stack, filename="processed_data/climate_stack.grd", overwrite=TRUE)
rm(list = c("mean_sum_rain", "mean_win_rain", "rel_humidity", "max_res_raster", "rasters")) # need mean_win_
```

Might be able to use model in:
raster::predict(climate_stack, model, type='response')

And now we can save it processed_data for easy creation later on.
## Create australia raster for cleaning
```{r}
australia_raster <- raster(extent(mean_win_temp), res = res(mean_win_temp))

# Set values to 1 where "mean_win_temp" is not NA, and 0 otherwise
australia_raster[] <- NA

# Set values to 1 where "mean_win_temp" is not NA, and 0 otherwise
australia_raster[!is.na(mean_win_temp)] <- 1
australia_raster[is.na(mean_win_temp)] <- 0
```

# Prepare Data

## Load raw data

Downloaded by ALA, with default settings on (e.g. spatially suspect records were excluded)
```{r}
toads <- read_csv("raw_data/occurrence/rhinella-marina-occurence.csv")
```
Could geo-reference the missing coordinate observations using the 'locality' column

```{r}
length(toads[!(!is.na(toads$decimalLatitude) & !is.na(toads$decimalLongitude)),])
```




## Clean Data

```{r}
clean <- toads |> 
  filter(country == "Australia" & !is.na(decimalLatitude) & !is.na(decimalLongitude))
clean
```

```{r}
georef <- subset(clean, (is.na(decimalLongitude) | is.na(decimalLatitude)) & ! is.na(locality) ) |> 
  dplyr::select(rightsHolder, stateProvince, locality, eventDate)
georef
```
So there are only 73 rows that could be georeferenced. According to https://docs.gbif.org/georeferencing-best-practices/1.0/en/ however, it is better to not georeference at all than georeference poorly. Given this data is so old

```{r}
cutoff <- function(x) {-0.5*x + 40}
ggplot(toads, aes(x=decimalLongitude, y=decimalLatitude, color=country)) +
  geom_point() +
  stat_function(fun=cutoff, colour='red')
```

```{r}
sp_clean <- clean
coordinates(sp_clean) <- c("decimalLongitude", "decimalLatitude")
```

Only take values on land

```{r}
is_land <- extract(australia_raster, sp_clean)

# Filter rows in the spatial data frame based on the raster values
clean <- clean[which(is_land == 1),]
```

REMOVED clean[which(is_land != 1),] ROWS

```{r}
cutoff <- function(x) {-0.5*x + 40}
ggplot(clean, aes(x=decimalLongitude, y=decimalLatitude)) +
  geom_point() +
  stat_function(fun=cutoff, colour='red')
```

Going to remove observations below the red line:

```{r}
clean <- clean |> 
  filter(decimalLatitude - cutoff(decimalLongitude) >= 0) # above red line above
```

```{r}
ggplot(clean, aes(x=decimalLongitude, y=decimalLatitude)) +
  geom_point()
```

Finally, there are no cane toads in Central Australia

```{r}
clean <- clean |> 
  filter(!(decimalLongitude < 135 & decimalLatitude < -22))
```

```{r}
ggplot(clean, aes(x=decimalLongitude, y=decimalLatitude)) +
  geom_point()
```

I'm happy with this! Would like to automate cleaning a bit further, by determining clusters? I'm sure there's a function online to do it easily.

## Create main df

Now create main dataframe
```{r}
df <- clean |> 
  dplyr::select(eventDate, year, stateProvince, locality, decimalLongitude, decimalLatitude,) |> 
  arrange(eventDate)
df <- df |> 
  rename(longitude = decimalLongitude,
         latitude = decimalLatitude)

df <- df[(!is.na(df$latitude) & !is.na(df$longitude)),]
sp_df <- df
coordinates(sp_df) <- c("longitude", "latitude")

head(sp_df)
```


```{r}
counts <- rasterize(sp_df, climate_stack, fun = "count", background=0) # cells without observation get a 0
toad_counts <- counts[["ID"]] # 1 per individual row
toad_count_df <- as.data.frame(toad_counts, xy = TRUE)
plot(toad_counts)
```


## EDA of df


There is no absence data:
```{r}
unique(toads$occurrenceStatus)
```

1900 records are likely wrong (1900-01-01?), In fact, an odd number of records occur on the first day of the month.

```{r}
head(df)
```

```{r}
ggplot(df, aes(x=yday(eventDate))) +
  geom_histogram()
```

```{r}
library(skimr)
library(GGally)
```
```{r}
skim(df)
```
```{r, warning=F, message=F}
df |> 
  dplyr::select(-locality) |> 
  ggpairs()
```
```{r}
ggplot(df, aes(x=longitude, y=latitude)) +
  geom_point()
```



```{r}
toads |> 
  arrange(eventDate) |> 
  head()
```

# Create cell_df

```{r}
unique(subset(sp_df, year < 2000)$year)
```

```{r}
create_cell_df <- function(data, years_up_to=2024, res=0.5) {
  data <- subset(data, year < years_up_to)
  toad_counts <- rasterize(data, climate_stack, fun = "count", background=0)[["ID"]] # 1 per individual row? (Check later), backgroun = 0 means cells with nothing get 0
  toad_count_df <- as.data.frame(toad_counts, xy = TRUE)
  cell_df <- cbind(toad_count_df, as.data.frame(extract(climate_stack, toad_count_df[,1:2], method='bilinear'))) # adds lats and longs
  cell_df <- na.omit(cell_df)
  rownames(cell_df) <- NULL
  
  cell_df <- cell_df |> 
    rename(longitude = "x",
           latitude = "y",
           n_toads = "ID")
  
  cell_df$ribbit <- cell_df$n_toads > 0
  
  return(cell_df)
}
```



```{r}
cell_df <- create_cell_df(sp_df, years_up_to=2024, res=0.5)
head(cell_df)
```



Could remove data from clear outlier observations?

What about data before 2010?

## Actual toad counts data

```{r}
ggplot(cell_df, aes(x=longitude, y=latitude, color=log10(n_toads))) +
  geom_point(size=1.2) +
  viridis::scale_color_viridis()
```

```{r}
toad_counts <- rasterize(sp_df, climate_stack, fun = "count", background=0)[["ID"]] # 1 per individual row? (Check later), backgroun = 0 means cells with nothing get 0
plot(log10(toad_counts))
```


# Machine learning


```{r split-data}
set.seed(12345)
n <- nrow(cell_df)
n_trains <- floor(0.7 * n)
train_idxs <- sample(1:n, n_trains)  # Sample 70% of rows for training
test_idxs <- setdiff(1:n, train_idxs)  # Use the remaining rows for testing

# Create training and testing dataframes
train <- cell_df[train_idxs, ]
test <- cell_df[test_idxs, ]
```

## Regression

```{r}
create_model <- function(data) {randomForest(n_toads ~ mean_win_temp + rel_humidity + mean_win_rain + mean_sum_rain, data=data)}
```

```{r}
rf_model1 <- randomForest(n_toads ~ mean_win_temp + rel_humidity + mean_win_rain + mean_sum_rain, data=train)

predictions1 <- predict(climate_stack, model = rf_model1)

# Visualize predictions
plot(log10(predictions1))
```


## Binary

```{r}
rf_model2 <- randomForest(as.factor(!ribbit) ~ mean_win_rain + mean_win_temp + mean_sum_rain + rel_humidity, data = train) # makes it binary. For some reason need the !?

# Might be to do with predicted2[,"TRUE"]

predictions2 <- predict(climate_stack, model = rf_model2, type='prob')

# Visualize predictions
plot(predictions2)
```

```{r}
rf_model3 <- randomForest(n_toads ~ mean_win_temp + rel_humidity + mean_win_rain + mean_sum_rain, 
                          data=train, classwt = )

predictions3 <- predict(climate_stack, model = rf_model3)

# Visualize predictions
plot(log10(predictions3))
```
predictions

# Model evaluation

```{r}
confusion_mtx = table(test$toads,test$model_toads) 
```

```{r}
# Plotting model 
plot(rf_model2) 
  
# Importance plot 
importance(rf_model2) 
  
# Variable importance plot 
varImpPlot(rf_model2) 
```

```{r}
# Plotting model 
plot(rf_model1) 
  
# Importance plot 
importance(rf_model1) 
  
# Variable importance plot 
varImpPlot(rf_model1) 
```

Model 2 is way better?

```{r}
hist(log10(predictions1))
```


# Future Predicting 

```{r}
millenium <- create_cell_df(sp_df, years_up_to=2000, res=0.4)
head(millenium)
```
```{r}
sum(millenium$n_toads) < sum(cell_df$n_toads)
```

```{r}
mill_model <- create_model(millenium)

predictions_m <- predict(climate_stack, mill_model)
```

```{r}
plot(log10(predictions1))
```
```{r}
res(australia_raster)
```


```{r}
plot(log10(predictions_m))
```

```{r}
millenium <- create_cell_df(df, years_to=2000, res=0.5)
head(millenium)



mill_model <- run_model(millenium)

millenium$predicted <- predict(mill_model, millenium)

ggplot(millenium, aes(x=decimalLongitude, y=decimalLatitude, color=log10(predicted))) +
  geom_point(size=1.8) +
  viridis::scale_color_viridis()
```



Varroa mites
Fire ants
Proximate Bayesian Modelling
Use already-made shapefiles of cane toad distributions

Amniote life history database


http://www.bom.gov.au/climate/maps/averages/rainfall/
