---
title: "Data Cleaning"
author: "Nicholas Boffa u7686660"
date: "2024-04-28"
output: html_document
---

# Load Libraries

```{r load-libraries}
library(tidyverse)
library(raster)
library(knitr)
library(randomForest)
library(rasterVis)
library(animation)
library(dbscan)
library(terra)
library(geodata)
library(sf)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Get WorldClim data

Data can be downloaded by running 

bioclim_data <- geodata::worldclim_global(var = "bio", res = 10, path = output_dir)



```{r}
# Specify the directory to save the downloaded files
output_dir <- "raw_data/climate"

# Download the 19 bioclimatic layers

bio_files <- list.files("raw_data/climate/wc2.1_10m", full.names = TRUE)
```


```{r}
bioclim_names <- c(
  "Annual Mean Temperature",            # bio1
  "Mean Diurnal Range",                 # bio2
  "Isothermality",                      # bio3
  "Temperature Seasonality",            # bio4
  "Max Temperature of Warmest Month",   # bio5
  "Min Temperature of Coldest Month",   # bio6
  "Temperature Annual Range",           # bio7
  "Mean Temperature of Wettest Quarter",# bio8
  "Mean Temperature of Driest Quarter", # bio9
  "Mean Temperature of Warmest Quarter",# bio10
  "Mean Temperature of Coldest Quarter",# bio11
  "Annual Precipitation",               # bio12
  "Precipitation of Wettest Month",     # bio13
  "Precipitation of Driest Month",      # bio14
  "Precipitation Seasonality",          # bio15
  "Precipitation of Wettest Quarter",   # bio16
  "Precipitation of Driest Quarter",    # bio17
  "Precipitation of Warmest Quarter",   # bio18
  "Precipitation of Coldest Quarter"    # bio19
)

# Read the bioclimatic layers into a RasterStack
bioclim_stack <- stack(bio_files)

# Assign the new names to the layers in the bioclim_stack
names(bioclim_stack) <- bioclim_names

xmin <- 113.0  # Westernmost point of mainland Australia
xmax <- 154.0  # Easternmost point of mainland Australia
ymin <- -44.0  # Southernmost point of mainland Australia
ymax <- -10.0  # Northernmost point of mainland Australia

base_extent <- c(xmin, xmax, ymin, ymax)

bioclim_stack <- crop(bioclim_stack, base_extent)
```



```{r}
australia_gadm <- gadm(country = "AUS", level = 0, path = tempdir())

# Convert to sf object and cast to polygons
australia_sf <- australia_gadm %>%
  st_as_sf() %>%
  st_cast("POLYGON")

# Calculate area and select the largest polygon (mainland Australia)
mainland_australia <- australia_sf %>%
  mutate(area = st_area(.)) %>%
  arrange(desc(area)) %>%
  slice(1)

# Convert the map to a Spatial object for masking
australia_spatial <- as(mainland_australia, "Spatial")

# Mask the bioclim_stack with the mainland Australia shapefile
bioclim_stack_masked <- mask(bioclim_stack, australia_spatial)

# Plot the result to verify
plot(bioclim_stack_masked)

writeRaster(bioclim_stack, "processed_data/bioclim_stack", filetype="GTiff", overwrite=TRUE)
```


# Get Image Raster Data



```{r}
bioclim_stack <- stack("processed_data/bioclim_stack.grd")
src_image <- "raw_data/breeding.png"
dst_image <- "processed_data/georef_breeding_image.tif"

image_raster <- rast(src_image) # have to use terra for image processing
ext(image_raster) <- base_extent
res(image_raster) <- res(bioclim_stack)
crs(image_raster) <- "EPSG:4326"

writeRaster(image_raster, dst_image, filetype="GTiff", overwrite=TRUE)
```



```{r}
image_raster <- rast(dst_image)
plot(image_raster)
```

Remove text from image using bullshit

```{r}
# Extract the RGB channels
red_channel <- raster(image_raster[[1]])
green_channel <- raster(image_raster[[2]])
blue_channel <- raster(image_raster[[3]])

black_mask <- (red_channel < 100 | green_channel < 100 | blue_channel > 100)

# Apply the mask to set black pixels to NA
red_channel[black_mask] <- NA
green_channel[black_mask] <- NA
blue_channel[black_mask] <- NA
blue_channel[blue_channel > 250] <- NA
blue_channel[is.na(blue_channel)] <- NA

plot(blue_channel) # green channel also works!?
```

```{r}
agged <- aggregate(blue_channel, fact=6, fun=median)
breeding <- !is.na(agged)
lat_mask <- breeding
lat_mask <- init(lat_mask, "y") > -20

breeding_corrected <- breeding
breeding_corrected[lat_mask == 1] <- 1
breeding_corrected <- mask(breeding_corrected, australia_spatial)
plot(breeding_corrected)
plot(australia_spatial, add = TRUE, border = "red")
```

Finally, we can see that there are some gaps still remaining

```{r}
plot(breeding_corrected == 0)
```

And so we fill them in

```{r}
fill_cells <- function(x) {
  if (is.na(x[5])) {
    return(NA)
  } else if (x[5] == 0 & all(x[-5] == 1 | is.na(x[-5]))) {
      return(1)
  } else {
      return(x[5])
  }
}

# Apply the function to the raster using focal
filled_raster <- focal(breeding_corrected, w=matrix(1, 3, 3), fun=fill_cells, na.policy='omit', pad=TRUE, padValue=0)

# Plot the original and filled rasters for comparison
par(mfrow=c(1,2))
plot(breeding_corrected, main="Original Raster")
plot(filled_raster, main="Filled Raster")
```

```{r}
plot(filled_raster == 0)
```

Not perfect, but pretty good

```{r}
raster::writeRaster(breeding_corrected, "processed_data/breeding.grd", overwrite=TRUE)
```


# Create Raster Brick

## Download .txt files

To obtain original .txt data, from the web:

1. Click the link for each file type, specified in the *table* below
2. Find the text saying "Download: Grid"
3. Click on the hyperlinked "Grid" to download


```{r}
table <- data.frame(
  Measurement = c("Mean Winter Temperature", "Mean Summer Rainfall", "Mean Winter Rainfall", "Mean Annual Relative Humidity at 9am"),
  Period = c("June to August 1991 to 2020", "December to February 1991 to 2020", "June to August 1991 to 2020", "1976 to 2005"),
  Link = c("[Mean Winter Temperature Data](http://www.bom.gov.au/climate/maps/averages/temperature/?maptype=mean&period=win&region=aus)",
           "[Mean Summer Rainfall Data](http://www.bom.gov.au/climate/maps/averages/rainfall/?period=sum&region=aus)",
           "[Mean Winter Rainfall Data](http://www.bom.gov.au/climate/maps/averages/rainfall/?period=win&region=aus)",
           "[Mean Annual Relative Humidity at 9am Data](http://www.bom.gov.au/climate/maps/averages/relative-humidity/)")
)

# Display table using kable
kable(table, format = "html", escape = FALSE)
```

## Load raster layers and make stack
```{r create-raster-brick}
mean_win_temp <- raster("raw_data/climate/mean_winter_temp.txt")
rel_humidity <- raster("raw_data/climate/rel_humidity_9am.txt")
mean_win_rain <- raster("raw_data/climate/mean_winter_rainfall.txt")
mean_sum_rain <- raster("raw_data/climate/mean_summer_rainfall.txt")

rasters <- list(mean_win_temp, rel_humidity, mean_win_rain, mean_sum_rain, swapped)

# Find max resolution raster
max_res <- max(res(mean_win_temp), res(rel_humidity), 
                  res(mean_win_rain), res(mean_sum_rain), res(swapped))

max_res_index <- which.max(c(res(mean_win_temp), res(rel_humidity), res(mean_win_rain), res(mean_sum_rain), res(swapped)))

max_res_raster <- rasters[[floor(max_res_index/2)]]

# Resample rasters to the extent and resolution of raster with max res
mean_win_temp <- resample(mean_win_temp, max_res_raster, method = "bilinear")
rel_humidity <- resample(rel_humidity, max_res_raster, method = "bilinear")
mean_win_rain <- resample(mean_win_rain, max_res_raster, method = "bilinear")
mean_sum_rain <- resample(mean_sum_rain, max_res_raster, method = "bilinear")
swapped <- resample(swapped, max_res_raster, method = "bilinear")

# Give themm all australia shape, using the fact that mean_win_temp is shaped like Australia

rel_humidity[is.na(mean_win_temp)] <- NA
mean_win_rain[is.na(mean_win_temp)] <- NA
mean_sum_rain[is.na(mean_win_temp)] <- NA
swapped[is.na(mean_win_temp)] <- NA
swapped[is.na(swapped) & !is.na(mean_win_temp)] <- 0

# Create a raster brick
climate_stack <- stack(mean_win_temp, rel_humidity, mean_win_rain, mean_sum_rain, swapped)
names(climate_stack) <- c("mean_win_temp", "rel_humidity", "mean_win_rain", "mean_sum_rain", "breeding")

# set resolution
desired_res <- 0.4
fact <- desired_res/res(climate_stack)
climate_stack <- aggregate(climate_stack, fact=fact)

plot(climate_stack)


writeRaster(climate_stack, filename="processed_data/climate_stack.grd", overwrite=TRUE)
rm(list = c("mean_sum_rain", "mean_win_rain", "rel_humidity", "max_res_raster", "rasters")) # need mean_win_
```

And now we can save it processed_data for easy creation later on.
## Create australia raster for cleaning
```{r}
land_raster <- raster(extent(mean_win_temp), res = res(mean_win_temp))

# Set values to 1 where "mean_win_temp" is not NA, and 0 otherwise
land_raster[] <- NA

# Set values to 1 where "mean_win_temp" is not NA, and 0 otherwise
land_raster[!is.na(mean_win_temp)] <- 1
land_raster[is.na(mean_win_temp)] <- 0
```

# Prepare Data

## Load raw data

Downloaded by ALA, with default settings on (e.g. spatially suspect records were excluded)
```{r}
toads <- read_csv("raw_data/occurrence/rhinella-marina-occurence.csv")
```
Could geo-reference the missing coordinate observations using the 'locality' column

```{r}
length(toads[!(!is.na(toads$decimalLatitude) & !is.na(toads$decimalLongitude)),])
```




## Clean Data

### Country removal
```{r}
clean <- toads |> 
  filter(country == "Australia" & !is.na(decimalLatitude) & !is.na(decimalLongitude))
clean
```

```{r}
georef <- subset(clean, (is.na(decimalLongitude) | is.na(decimalLatitude)) & ! is.na(locality) ) |> 
  dplyr::select(rightsHolder, stateProvince, locality, eventDate)
georef
```

So there are only 73 rows that could be georeferenced. According to https://docs.gbif.org/georeferencing-best-practices/1.0/en/ however, it is better to not georeference at all than georeference poorly. Given this data is so old


Only take values on land

```{r}
sp_clean <- clean
coordinates(sp_clean) <- c("decimalLongitude", "decimalLatitude")
is_land <- raster::extract(land_raster, sp_clean)

# Filter rows in the spatial data frame based on the raster values
clean <- clean[which(is_land == 1),]
```


REMOVED clean[which(is_land != 1),] ROWS


```{r}
clusters <- dbscan(clean[, c("decimalLongitude", "decimalLatitude")], eps = 2.5, minPts = 3) # arguments heavily affect result

# Add cluster IDs to your data frame
clean$cluster <- clusters$cluster

# Create a ggplot of the clusters
ggplot(clean[, c("decimalLongitude", "decimalLatitude", "cluster")], aes(x = decimalLongitude, y = decimalLatitude, color = as.factor(cluster))) +
  geom_point(aes(size = 3), alpha = 0.6) +
  labs(title = "DBSCAN Clustering of Geographical Data", x = "Longitude", y = "Latitude") +
  theme_minimal() +
  theme(legend.position='none')
```

The yellow matches current distribution, unlike the cleaned data https://www.researchgate.net/publication/320257212_Effects_of_invasion_history_on_physiological_responses_to_immune_system_activation_in_invasive_Australian_cane_toads

```{r}
is_large <- table(clean$cluster) > 100
large_clusters <- is_large[is_large]

clean <- clean |> 
  filter(cluster %in% large_clusters)
```


```{r}
ggplot(clean, aes(x=decimalLongitude, y=decimalLatitude)) +
  geom_point()
```




## Create main df

Now create main dataframe
```{r}
df <- clean |> 
  dplyr::select(eventDate, year, stateProvince, locality, decimalLongitude, decimalLatitude,) |> 
  arrange(eventDate)
df <- df |> 
  rename(longitude = decimalLongitude,
         latitude = decimalLatitude)

head(df)

write_csv(df, "processed_data/clean_toads.csv")
```







