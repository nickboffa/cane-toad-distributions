---
title: "Data Cleaning"
author: "Nicholas Boffa u7686660"
date: "2024-04-28"
output: html_document
---

# Load Libraries

```{r load-libraries}
library(tidyverse)
library(raster)
library(knitr)
library(randomForest)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Create Raster Brick
## Download .txt files

To obtain original .txt data, from the web:

1. Click the link for each file type, specified in the *table* below
2. Find the text saying "Download: Grid"
3. Click on the hyperlinked "Grid" to download


```{r}
table <- data.frame(
  Measurement = c("Mean Winter Temperature", "Mean Summer Rainfall", "Mean Winter Rainfall", "Mean Annual Relative Humidity at 9am"),
  Period = c("June to August 1991 to 2020", "December to February 1991 to 2020", "June to August 1991 to 2020", "1976 to 2005"),
  Link = c("[Mean Winter Temperature Data](http://www.bom.gov.au/climate/maps/averages/temperature/?maptype=mean&period=win&region=aus)",
           "[Mean Summer Rainfall Data](http://www.bom.gov.au/climate/maps/averages/rainfall/?period=sum&region=aus)",
           "[Mean Winter Rainfall Data](http://www.bom.gov.au/climate/maps/averages/rainfall/?period=win&region=aus)",
           "[Mean Annual Relative Humidity at 9am Data](http://www.bom.gov.au/climate/maps/averages/relative-humidity/)")
)

# Display table using kable
kable(table, format = "html", escape = FALSE)
```


## Load raster layers and make stack
```{r create-raster-brick}
mean_win_temp <- raster("raw_data/climate/mean_winter_temp.txt")
rel_humidity <- raster("raw_data/climate/rel_humidity_9am.txt")
mean_win_rain <- raster("raw_data/climate/mean_winter_rainfall.txt")
mean_sum_rain <- raster("raw_data/climate/mean_summer_rainfall.txt")

rasters <- list(mean_win_temp, rel_humidity, mean_win_rain, mean_sum_rain)

# Find max resolution raster
max_res <- max(res(mean_win_temp), res(rel_humidity), 
                  res(mean_win_rain), res(mean_sum_rain))

max_res_index <- which.max(c(res(mean_win_temp), res(rel_humidity), res(mean_win_rain), res(mean_sum_rain)))

max_res_raster <- rasters[[max_res_index]]

# Resample rasters to the extent and resolution of raster with max res
mean_win_temp <- resample(mean_win_temp, max_res_raster, method = "bilinear")
rel_humidity <- resample(rel_humidity, max_res_raster, method = "bilinear")
mean_win_rain <- resample(mean_win_rain, max_res_raster, method = "bilinear")
mean_sum_rain <- resample(mean_sum_rain, max_res_raster, method = "bilinear")

# Give themm all australia shape, using the fact that mean_win_temp is shaped like Australia

rel_humidity[is.na(mean_win_temp)] <- NA
mean_win_rain[is.na(mean_win_temp)] <- NA
mean_sum_rain[is.na(mean_win_temp)] <- NA

# Create a raster brick
climate_stack <- stack(mean_win_temp, rel_humidity, mean_win_rain, mean_sum_rain)
names(climate_stack) <- c("mean_win_temp", "rel_humidity", "mean_win_rain", "mean_sum_rain")

# set resolution
desired_res <- 0.4
fact <- desired_res/res(climate_stack)
climate_stack <- aggregate(climate_stack, fact=fact)

plot(climate_stack)


writeRaster(climate_stack, filename="processed_data/climate_stack.grd", overwrite=TRUE)
rm(list = c("mean_sum_rain", "mean_win_rain", "rel_humidity", "max_res_raster", "rasters")) # need mean_win_
```

Might be able to use model in:
raster::predict(climate_stack, model, type='response')

And now we can save it processed_data for easy creation later on.
## Create australia raster for cleaning
```{r}
australia_raster <- raster(extent(mean_win_temp), res = res(mean_win_temp))

# Set values to 1 where "mean_win_temp" is not NA, and 0 otherwise
australia_raster[] <- NA

# Set values to 1 where "mean_win_temp" is not NA, and 0 otherwise
australia_raster[!is.na(mean_win_temp)] <- 1
australia_raster[is.na(mean_win_temp)] <- 0
```

# Prepare Data

## Load raw data

Downloaded by ALA, with default settings on (e.g. spatially suspect records were excluded)
```{r}
toads <- read_csv("raw_data/occurrence/rhinella-marina-occurence.csv")
```
Could geo-reference the missing coordinate observations using the 'locality' column

```{r}
length(toads[!(!is.na(toads$decimalLatitude) & !is.na(toads$decimalLongitude)),])
```




## Clean Data

```{r}
clean <- toads |> 
  filter(country == "Australia" & !is.na(decimalLatitude) & !is.na(decimalLongitude))
clean
```

```{r}
georef <- subset(clean, (is.na(decimalLongitude) | is.na(decimalLatitude)) & ! is.na(locality) ) |> 
  dplyr::select(rightsHolder, stateProvince, locality, eventDate)
georef
```
So there are only 73 rows that could be georeferenced. According to https://docs.gbif.org/georeferencing-best-practices/1.0/en/ however, it is better to not georeference at all than georeference poorly. Given this data is so old

```{r}
cutoff <- function(x) {-0.5*x + 40}
ggplot(toads, aes(x=decimalLongitude, y=decimalLatitude, color=country)) +
  geom_point() +
  stat_function(fun=cutoff, colour='red')
```

```{r}
sp_clean <- clean
coordinates(sp_clean) <- c("decimalLongitude", "decimalLatitude")
```

Only take values on land

```{r}
is_land <- extract(australia_raster, sp_clean)

# Filter rows in the spatial data frame based on the raster values
clean <- clean[which(is_land == 1),]
```

REMOVED clean[which(is_land != 1),] ROWS

```{r}
cutoff <- function(x) {-0.5*x + 40}
ggplot(clean, aes(x=decimalLongitude, y=decimalLatitude)) +
  geom_point() +
  stat_function(fun=cutoff, colour='red')
```

Going to remove observations below the red line:

```{r}
clean <- clean |> 
  filter(decimalLatitude - cutoff(decimalLongitude) >= 0) # above red line above
```

```{r}
ggplot(clean, aes(x=decimalLongitude, y=decimalLatitude)) +
  geom_point()
```

Finally, there are no cane toads in Central Australia

```{r}
clean <- clean |> 
  filter(!(decimalLongitude < 135 & decimalLatitude < -22))
```

```{r}
ggplot(clean, aes(x=decimalLongitude, y=decimalLatitude)) +
  geom_point()
```

I'm happy with this! Would like to automate cleaning a bit further, by determining clusters? I'm sure there's a function online to do it easily.

## Create main df

Now create main dataframe
```{r}
df <- clean |> 
  dplyr::select(eventDate, year, stateProvince, locality, decimalLongitude, decimalLatitude,) |> 
  arrange(eventDate)
df <- df |> 
  rename(longitude = decimalLongitude,
         latitude = decimalLatitude)

df <- df[(!is.na(df$latitude) & !is.na(df$longitude)),]
sp_df <- df
coordinates(sp_df) <- c("longitude", "latitude")

head(sp_df)
```


```{r}
counts <- rasterize(sp_df, climate_stack, fun = "count", background=0) # cells without observation get a 0
toad_counts <- counts[["ID"]] # 1 per individual row
toad_count_df <- as.data.frame(toad_counts, xy = TRUE)
plot(toad_counts)
```


## EDA of df


There is no absence data:
```{r}
unique(toads$occurrenceStatus)
```

1900 records are likely wrong (1900-01-01?), In fact, an odd number of records occur on the first day of the month.

```{r}
head(df)
```

```{r}
ggplot(df, aes(x=yday(eventDate))) +
  geom_histogram()
```

```{r}
library(skimr)
library(GGally)
```
```{r}
skim(df)
```
```{r, warning=F, message=F}
df |> 
  dplyr::select(-locality) |> 
  ggpairs()
```
```{r}
ggplot(df, aes(x=longitude, y=latitude)) +
  geom_point()
```



```{r}
toads |> 
  arrange(eventDate) |> 
  head()
```

# Create cell_df

```{r}
unique(subset(sp_df, year < 2000)$year)
```

```{r}
create_cell_df <- function(data, years_up_to=2024, res=0.5) {
  data <- subset(data, year < years_up_to)
  toad_counts <- rasterize(data, climate_stack, fun = "count", background=0)[["ID"]] # 1 per individual row? (Check later), backgroun = 0 means cells with nothing get 0
  toad_count_df <- as.data.frame(toad_counts, xy = TRUE)
  cell_df <- cbind(toad_count_df, as.data.frame(extract(climate_stack, toad_count_df[,1:2], method='bilinear'))) # adds lats and longs
  cell_df <- na.omit(cell_df)
  rownames(cell_df) <- NULL
  
  cell_df <- cell_df |> 
    rename(longitude = "x",
           latitude = "y",
           n_toads = "ID")
  
  cell_df$ribbit <- cell_df$n_toads > 0
  
  return(cell_df)
}
```



```{r}
cell_df <- create_cell_df(sp_df, years_up_to=2024, res=0.5)
head(cell_df)
```



Could remove data from clear outlier observations?

What about data before 2010?

## Actual toad counts data

```{r}
ggplot(cell_df, aes(x=longitude, y=latitude, color=log10(n_toads))) +
  geom_point(size=1.2) +
  viridis::scale_color_viridis()
```

```{r}
toad_counts <- rasterize(sp_df, climate_stack, fun = "count", background=0)[["ID"]] # 1 per individual row? (Check later), backgroun = 0 means cells with nothing get 0
plot(log10(toad_counts))
```


# Machine learning


```{r split-data}
set.seed(12345)
n <- nrow(cell_df)
n_trains <- floor(0.7 * n)
train_idxs <- sample(1:n, n_trains)  # Sample 70% of rows for training
test_idxs <- setdiff(1:n, train_idxs)  # Use the remaining rows for testing

# Create training and testing dataframes
train <- cell_df[train_idxs, ]
test <- cell_df[test_idxs, ]
```

## Regression

```{r}
create_model <- function(data) {randomForest(n_toads ~ mean_win_temp + rel_humidity + mean_win_rain + mean_sum_rain, data=data)}
```

```{r}
rf_model1 <- randomForest(n_toads ~ mean_win_temp + rel_humidity + mean_win_rain + mean_sum_rain, data=train)

predictions1 <- predict(climate_stack, model = rf_model1)

# Visualize predictions
plot(log10(predictions1))
```


## Binary

```{r}
rf_model2 <- randomForest(as.factor(!ribbit) ~ mean_win_rain + mean_win_temp + mean_sum_rain + rel_humidity, data = train) # makes it binary. For some reason need the !?

# Might be to do with predicted2[,"TRUE"]

predictions2 <- predict(climate_stack, model = rf_model2, type='prob')

# Visualize predictions
plot(predictions2)
```

```{r}
rf_model3 <- randomForest(n_toads ~ mean_win_temp + rel_humidity + mean_win_rain + mean_sum_rain, 
                          data=train, classwt = )

predictions3 <- predict(climate_stack, model = rf_model3)

# Visualize predictions
plot(log10(predictions3))
```
predictions

# Model evaluation

```{r}
confusion_mtx = table(test$toads,test$model_toads) 
```

```{r}
# Plotting model 
plot(rf_model2) 
  
# Importance plot 
importance(rf_model2) 
  
# Variable importance plot 
varImpPlot(rf_model2) 
```

```{r}
# Plotting model 
plot(rf_model1) 
  
# Importance plot 
importance(rf_model1) 
  
# Variable importance plot 
varImpPlot(rf_model1) 
```

Model 2 is way better?

```{r}
hist(log10(predictions1))
```


# Future Predicting 

```{r}
millenium <- create_cell_df(sp_df, years_up_to=2000, res=0.4)
head(millenium)
```
```{r}
sum(millenium$n_toads) < sum(cell_df$n_toads)
```

```{r}
mill_model <- create_model(millenium)

predictions_m <- predict(climate_stack, mill_model)
```

```{r}
plot(log10(predictions1))
```
```{r}
res(australia_raster)
```


```{r}
plot(log10(predictions_m))
```

# Time

1. Create rasterbrick over time

```{r}
lat_mask <- mean_win_temp
lat_mask <- init(lat_mask, "y") < -39.3  # Creates a logical mask for latitudes less than -40

# Apply the mask to the raster
mainland <- mask(mean_win_temp, lat_mask, maskvalue=1)
mainland_agg <- aggregate(mainland, fact=40)
plot(mainland_agg)

australia_raster <- raster(extent(mainland_agg), res = res(mainland_agg))

# Set values to 1 where "mean_win_temp" is not NA, and 0 otherwise
australia_raster[] <- NA

# Set values to 1 where "mean_win_temp" is not NA, and 0 otherwise
australia_raster[!is.na(mainland_agg)] <- 1
australia_raster[is.na(mainland_agg)] <- 0

rm(list = c("mainland", "mainland_agg", "lat_mask")) #"mean_win_temp",
plot(australia_raster)
```


```{r}
predictions2_agg <- resample(predictions2, australia_raster)
predictions1_agg <- resample(predictions1, australia_raster)

logged <- log10(predictions1)
input <- sqrt(predictions2_agg)

normalised <- (input - minValue(input))/(maxValue(input) - minValue(input))
normalised[which(is.na(normalised[]))] <- 0

affinities <- (2*normalised - 1) # -1 to 1
plot(affinities)
```

# Use OOP

```{r}
library(R6)
```

```{r}
Toad <- R6Class("toad",
  public = list(
    pos=NULL,
    energy=NULL,
    id=NULL,
    # Constructor method
    initialize = function(pos, energy, id) {
      self$pos <- pos
      self$energy <- energy
      self$id <- id
    },
    move = function() {
      # Determine where it can move to that's on land
      indices <- adjacent(australia_raster, cell = self$pos, directions = 8, pairs=TRUE)[,2]
      neighboring_cells <- australia_raster[indices]
      names(neighboring_cells) <- indices
      move_options <- as.numeric(names(neighboring_cells[which(neighboring_cells == 1)])) # list of cells that are still on land
      
      # Pick destination and move it there
      destination <- sample(move_options, 1) # prob doesn't need to sum to 1 btw
      self$pos <- destination
    },
    update_energy = function() {
      self$energy <- self$energy + max_abs_delta_energy*affinities[self$pos]
      if (self$energy > 1) {self$energy <- 1}
      if (self$energy < 0) {self$energy <- 0}
    },
    die = function() {
        remove_toad <- function(any_toad) {
          any_toad$id != self$id
        }
        # Remove the toad with the specified id
        alive_toads <- Filter(remove_toad, alive_toads)
    }
  )
)
```

      n_toads_destination <- table(sapply(alive_toads, function(t) t$pos == destination))['TRUE'] # could be na
      if (is.na(n_toads_destination) | n_toads_destination > 10) {
        self$die
      }
      else {
        self$pos <- destination
      }



```{r}
update_tracker <- function(tracker, toad_list) {
  tracker[] <- 0
  tracker[australia_raster == 0] <- NA
  for (toad in toad_list) {
    tracker[toad$pos] <- tracker[toad$pos] + 1
  }
  return(tracker)
}
```

```{r}
start <- cellFromXY(australia_raster, c(145.7844, -17.09833)) # actual start of cane toad invasion
start
```

```{r}
max_abs_delta_energy <- 0.5
init_energy <- 0.9
repr_limit <- 0.5
die_limit <- 0.2
steps_per_day <- 3

n_ticks <- 30
# setup
trackers <- vector("list", length = n_ticks - 1)
tracker <- raster(extent(australia_raster), res = res(australia_raster))
tracker[] <- 0

alive_toads <- c(Toad$new(pos = start, energy = init_energy, id=1))
last_id <- 1

for (tick in 1:n_ticks) {
  for (toad in alive_toads) { # what happens when alive_toads is updated during?
    for (m in 1:steps_per_day) {toad$move()}
    toad$update_energy() 
    if (toad$energy > repr_limit) { # reproduce
      new_id <- last_id + 1
      last_id <- new_id
      alive_toads <- c(alive_toads, Toad$new(pos = toad$pos, energy = init_energy, id=new_id))
    }
    if (toad$energy < die_limit) { # die
      remove_toad <- function(any_toad) {
          any_toad$id != toad$id
        }
        # Remove the toad with the specified id
        alive_toads <- Filter(remove_toad, alive_toads)
    }
  }
  
  print(length(alive_toads))
  alive_toads <- remove_excess(alive_toads)
  print(length(alive_toads))
  
  tracker <- update_tracker(tracker, alive_toads)
  trackers[[tick]] <- tracker
  
  print(paste(tick, length(alive_toads)))
  
  if (length(alive_toads) == 0) {
    break
  }
  
}

plotting <- trackers[[tick]] + 0.0005*length(alive_toads)*australia_raster
plot(plotting)
```


```{r}
remove_excess <- function(toads_list) {
  # Count the occurrences of each 'pos' in the list
  pos_counts <- table(sapply(toads_list, function(t) t$pos))
  
  # Initialize a list to store filtered toads
  filtered_toads <- list()
  
  # Loop through each unique 'pos'
  for (pos in names(pos_counts)) {
    # Get the first 10 toads for the current 'pos'
    toads_for_pos <- toads_list[sapply(toads_list, function(t) t$pos == pos)][1:min(7, pos_counts[pos])]
    
    # Add the filtered toads to the list
    filtered_toads <- c(filtered_toads, toads_for_pos)
  }
  
  return(filtered_toads)
}
```
